{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39de21c",
   "metadata": {},
   "source": [
    "Concrete_cracks_identifer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864051f1",
   "metadata": {},
   "source": [
    "This code was done in colab so tweak appropriately for jupyter ;follow notes on creating appropriate folder structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea236aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90743d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### kaggle dataset https://www.kaggle.com/datasets/arnavr10880/concrete-crack-images-for-classification\n",
    "### Referenced an exercise I completed on kaggle https://www.kaggle.com/code/evansataforson/exercise-custom-convnets/edit\n",
    "import zipfile\n",
    "\n",
    "# Specify the file path and extraction directory (replace with your actual paths)\n",
    "file_path = '/content/drive/MyDrive/ML_DATA/concrete_crack_data/archive (1).zip'\n",
    "#file_path = '/content/archive (1).zip' #use this when working locally the archive file can be got from the dataset link\n",
    "extract_dir = '/content/concrete_images'\n",
    "\n",
    "try:\n",
    "  # Attempt to extract the zip file\n",
    "  with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "  print(f\"Extracted files from '{file_path}' to '{extract_dir}' successfully.\")\n",
    "except Exception as e:\n",
    "  # Handle potential errors during extraction\n",
    "  print(f\"Error occurred during extraction: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "  #########\n",
    "\n",
    "#### splitting data into folders\n",
    "\n",
    "import os\n",
    "from shutil import move\n",
    "\n",
    "# Define base directory (assuming you mounted your drive)\n",
    "#base_dir = \"/content/concrete_images\"  # Replace with your base directory if mounted\n",
    "\n",
    "base_dir = \"/content\"\n",
    "# Define subfolder names (modify if needed)\n",
    "data_dir = \"concrete_images\"  # Assuming data is in a subfolder within the base directory\n",
    "train_dir = \"train\"\n",
    "val_dir = \"validation\"\n",
    "test_dir = \"test\"\n",
    "\n",
    "# Define class folders within data directory (assuming only Negative and Positive)\n",
    "class_folders = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Define the split ratio (e.g., 70% train, 15% validation, 15% test--- playing with 0.05. 0.02 and 0.93)\n",
    "#train_ratio = 0.7\n",
    "#val_ratio = 0.15\n",
    "#test_ratio = 0.15\n",
    "\n",
    "# Define the split ratio (--- playing with 0.05. 0.02 and 0.93 so it runs fast in colab the above setting should be used)\n",
    "train_ratio = 0.05\n",
    "val_ratio = 0.02\n",
    "test_ratio = 0.93\n",
    "\n",
    "\n",
    "def split_data(class_folder):\n",
    "  # Get all image file paths for the class\n",
    "  class_path = os.path.join(base_dir, data_dir, class_folder)\n",
    "  all_files = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "\n",
    "  # Split the data into train, validation, and test sets\n",
    "  num_files = len(all_files)\n",
    "  num_train = int(num_files * train_ratio)\n",
    "  num_val = int(num_files * val_ratio)\n",
    "  num_test = int(num_files * test_ratio)\n",
    "  train_files, val_files, test_files = all_files[:num_train], all_files[num_train:num_train+num_val], all_files[num_train+num_val:]\n",
    "\n",
    "  # Create train, validation, and test directories for the class within data_dir\n",
    "  os.makedirs(os.path.join(base_dir, data_dir, train_dir, class_folder), exist_ok=True)\n",
    "  os.makedirs(os.path.join(base_dir, data_dir, val_dir, class_folder), exist_ok=True)\n",
    "  os.makedirs(os.path.join(base_dir, data_dir, test_dir, class_folder), exist_ok=True)\n",
    "\n",
    "  # Move images to respective directories\n",
    "  for file in train_files:\n",
    "    move(file, os.path.join(base_dir, data_dir, train_dir, class_folder))\n",
    "\n",
    "  for file in val_files:\n",
    "    move(file, os.path.join(base_dir, data_dir, val_dir, class_folder))\n",
    "\n",
    "  for file in test_files:\n",
    "    move(file, os.path.join(base_dir, data_dir, test_dir, class_folder))\n",
    "\n",
    "  print(f\"Successfully split {class_folder} images into train, validation, and test sets.\")\n",
    "\n",
    "# Loop through each class folder and perform splitting\n",
    "for class_folder in class_folders:\n",
    "  split_data(class_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5870418",
   "metadata": {},
   "source": [
    "Setting up loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################set up\n",
    " # Setup feedback system\n",
    "#from learntools.core import binder\n",
    "#binder.bind(globals())\n",
    "#from learntools.computer_vision.ex5 import *\n",
    "\n",
    "# Imports\n",
    "#import os, warnings\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "\n",
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    '/content/concrete_images/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[227, 227],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    '/content/concrete_images/validation',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[227, 227],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1df38",
   "metadata": {},
   "source": [
    "Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df90444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Block One\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n",
    "                  input_shape=[227, 227, 3]),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Three\n",
    "    # YOUR CODE HERE\n",
    "    layers.Conv2D(filters=227, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=227, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b829bb52",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867c0bf",
   "metadata": {},
   "source": [
    "Test Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=50, should be used instead of 5 which is used to make it run faster in colab\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00487b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a54fc",
   "metadata": {},
   "source": [
    "Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "# Load a test image\n",
    "test_image_path = '/content/concrete_images/test/Positive/00007.jpg'\n",
    "img = load_img(test_image_path, target_size=(227, 227))\n",
    "\n",
    "# Preprocess the image (replace with your specific preprocessing steps)\n",
    "test_image = img_to_array(img)\n",
    "#test_image = test_image / 255.0  # Normalize pixel values (assuming this was done during training)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Predict on the test image\n",
    "predictions = model.predict(test_image)\n",
    "\n",
    "# Interpret predictions for classification (assuming model predicts class probabilities)\n",
    "predicted_class = np.argmax(predictions[0])  # Get index of class with highest probability\n",
    "#class_names = ['Positive', 'Negative']  # Replace with your actual class names (if applicable)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Hide axes for a cleaner presentation (optional)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Predicted class: {class_folders[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9193014",
   "metadata": {},
   "source": [
    "Most of the code down now focuses solely on google drive with colab so would need modification for jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save Model to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f351360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "# Mount your Google Drive (replace with authentication steps if needed)\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# Define the path to save the model within your Google Drive (replace with your desired location)\n",
    "#model_path = \"/content/gdrive/My Drive/concrete_images/saved_models\"\n",
    "model_path =\"/content/drive/MyDrive/ML_DATA/concrete_crack_data/saved_models\"\n",
    "os.makedirs(model_path, exist_ok=True)  # Create directory if it doesn't exist (optional)\n",
    "\n",
    "# Save the model using tf.keras.models.save\n",
    "model.save(model_path, save_format=\"tf\")\n",
    "\n",
    "# Get the base filename (without directory path) of the saved model\n",
    "saved_model_filename = os.path.basename(model_path)\n",
    "\n",
    "# Print the saved model name\n",
    "print(f\"Model saved successfully to Google Drive: {saved_model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ea65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load model from Google drive and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "# Mount your Google Drive (replace with authentication steps if needed)\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# Define the path where you saved the model within your Google Drive\n",
    "model_path = \"/content/drive/MyDrive/ML_DATA/concrete_crack_data/saved_models\"  # Replace with your path\n",
    "\n",
    "# Load the saved model from Google Drive\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"Model loaded successfully from Google Drive!\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a test image\n",
    "test_image_path_local = '/content/concrete_images/test/Positive/00007.jpg'\n",
    "img = load_img(test_image_path_local, target_size=(227, 227))\n",
    "\n",
    "# Preprocess the image (replace with your specific preprocessing steps)\n",
    "test_image_val = img_to_array(img)\n",
    "#test_image = test_image / 255.0  # Normalize pixel values (assuming this was done during training)\n",
    "test_image_val = np.expand_dims(test_image_val, axis=0)\n",
    "\n",
    "\n",
    "predictions = loaded_model.predict(test_image_val)\n",
    "\n",
    "# Interpret predictions for classification (assuming model predicts class probabilities)\n",
    "predicted_class = np.argmax(predictions[0])  # Get index of class with highest probability\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Hide axes for a cleaner presentation (optional)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Predicted class: {class_folders[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
